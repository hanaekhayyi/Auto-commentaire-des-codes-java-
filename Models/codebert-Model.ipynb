{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"***How to Create an Automatic Code Comment Generator using NLP:***","metadata":{}},{"cell_type":"markdown","source":"## A propos de notre projet","metadata":{}},{"cell_type":"markdown","source":"Bonjour, dans ce projet on *vas* affiner un modèle basé sur RoBERTa qui a été entraîné sur des données de code pour générer automatiquement des commentaires pour le code !\n","metadata":{}},{"cell_type":"markdown","source":"## Données\n\n\nLe jeu de données https://github.com/xing-hu/DeepCom/blob/master/data.7z du projet DeepCom contient des ressources pour l'entraînement et l'évaluation des modèles de génération de commentaires de code. Il comprend des paires de code source et leurs commentaires correspondants, ce qui permet de développer et de tester des modèles capables de générer automatiquement des commentaires pour le code source. Vous pouvez accéder et télécharger ce jeu de données à partir du repository GitHub de DeepCom.","metadata":{}},{"cell_type":"markdown","source":"## CodeBERT\nLe modèle préentraîné que nous allons affiner provient de l'incroyable article de la division de recherche de Microsoft intitulé CodeBERT: A Pre-Trained Model for Programming and Natural Languages. Ce modèle a  utilisé le jeu de données  pour générer des commentaires, il l'a utilisé pour enseigner à un modèle basé sur RoBERTa à représenter le code et le langage naturel de manière utile. Cette pratique consistant à apprendre à ces grands modèles de langage à représenter le texte de manière utile est désormais courante, car ces représentations se sont révélées utiles pour affiner ces modèles sur d'autres tâches. L'article sur CodeBERT a montré que ces représentations sont utiles en les affinant pour la recherche de code et la génération de commentaires, exactement ce que nous allons faire ! La différence entre leur tâche de génération de commentaires et la nôtre est que nous effectuerons un peu plus de prétraitement et notre modèle pourra générer des commentaires en ligne pour des extraits de code et pas seulement des commentaires au niveau des méthodes.\n\n\nAlors, comment CodeBERT apprend-il ces représentations ? Il combine deux objectifs d'entraînement différents qui se sont révélés utiles pour le langage naturel. L'objectif de modélisation de langue masquée (MLM), qui provient de l'article original BERT, et l'objectif de détection de token remplacé (RTD), qui provient de l'article ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators. L'objectif MLM consiste à masquer aléatoirement des parties du texte que nous fournissons au modèle et à demander au modèle de prédire ces parties masquées. L'objectif RTD consiste à remplacer des tokens aléatoires dans le texte et à demander au modèle de déterminer quels tokens ont été remplacés. Cependant, pour rendre la tâche plus difficile pour le modèle, ces tokens remplacés tentent d'être des alternatives plausibles et non juste des mots aléatoires. Le modèle CodeBERT a en fait utilisé un modèle basé sur des n-grammes pour générer ces alternatives, tandis que l'article ELECTRA a utilisé un petit modèle basé sur BERT.\n\n\n![ELECTRA Pretraining Objective](https://nathancooper.io/i-am-a-nerd/images/electra.png) (From ELECTRA Paper)\n\n\nAu lieu d'utiliser uniquement le langage naturel pour appliquer ces objectifs d'entraînement, CodeBERT a utilisé le code et les docstrings. Cela a permis au modèle CodeBERT d'apprendre une représentation utile du code qui pourrait être utilisée pour d'autres tâches.\n","metadata":{}},{"cell_type":"markdown","source":" Importe les bibliothèques nécessaires pour la manipulation des fichiers, l'analyse de données, la visualisation, et le traitement du langage naturel.","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom typing import List\nimport seaborn as sns\nimport re\nfrom typing import Optional\nimport numpy as np\nfrom collections import Counter\nfrom statistics import mean, median, stdev\nfrom transformers import AutoTokenizer","metadata":{"id":"WNflrZpnIp70","executionInfo":{"status":"ok","timestamp":1723802016000,"user_tz":-60,"elapsed":6686,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"execution":{"iopub.status.busy":"2024-08-27T08:18:53.248103Z","iopub.execute_input":"2024-08-27T08:18:53.248403Z","iopub.status.idle":"2024-08-27T08:18:59.058328Z","shell.execute_reply.started":"2024-08-27T08:18:53.248370Z","shell.execute_reply":"2024-08-27T08:18:59.057561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:19:10.049268Z","iopub.execute_input":"2024-08-27T08:19:10.050078Z","iopub.status.idle":"2024-08-27T08:19:10.056859Z","shell.execute_reply.started":"2024-08-27T08:19:10.050038Z","shell.execute_reply":"2024-08-27T08:19:10.055723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n****Affichage du contenu du fichier test****","metadata":{}},{"cell_type":"code","source":"filename = '/kaggle/input/code_comments/data/data/test.json'\n#chemin actuel du fichier\n\n# Lire et décoder chaque ligne JSON individuellement\ndata = []\nwith open(filename) as f:\n    for line in f:\n        try:\n            data.append(json.loads(line))\n        except json.JSONDecodeError as e:\n            print(f\"Erreur lors du décodage de la ligne : {e}\")\n\n# Afficher les 5 premiers éléments du fichier JSON\nfor i in data[:5]:\n    print(i)","metadata":{"id":"6L6PddLBIwUh","executionInfo":{"status":"ok","timestamp":1723802017445,"user_tz":-60,"elapsed":1449,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"ebae9753-d9ab-4a1b-a6d5-05d220212de5","execution":{"iopub.status.busy":"2024-08-27T08:19:28.049080Z","iopub.execute_input":"2024-08-27T08:19:28.049882Z","iopub.status.idle":"2024-08-27T08:19:28.519339Z","shell.execute_reply.started":"2024-08-27T08:19:28.049841Z","shell.execute_reply":"2024-08-27T08:19:28.518444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Telechargement des donnees dans une dataFrame Pandas****\n","metadata":{}},{"cell_type":"code","source":"def jsonl_to_dataframe(file_path, columns=['code', 'nl']):\n    \"\"\"Telechargement du JSON lignes file dans pandas DataFrame.\"\"\"\n    df = pd.read_json(file_path, orient='records', lines=True)\n    return df[columns]\n\ndef get_dfs(path: Path) -> List[pd.DataFrame]:\n    \"\"\"convertir les differents data splits en dataframe pandas\"\"\"\n    #path est le chemin du folder qui stocke les differents splits de types json il est de type Path\n    dfs = []\n    for split in [\"train.json\", \"valid.json\", \"test.json\"]:\n        file_path = path / split\n        if not file_path.exists():\n            print(f\"File not found: {file_path}\")\n            dfs.append(pd.DataFrame(columns=['mthd', 'cmt']))  # Créer un DataFrame vide pour ce split\n        else:\n            df = jsonl_to_dataframe(file_path)\n            df = df.rename(columns={'code': 'mthd', 'nl': 'cmt'})\n            dfs.append(df)\n\n    return dfs\n\n# Chemin vers les fichiers\npath = Path('/kaggle/input/code_comments/data/data')\n\n# Charger les DataFrames\ndf_trn, df_val, df_tst = get_dfs(path)\n\n#afficher la taille avant l'echantillonage\nprint(len(df_trn), len(df_val), len(df_tst))\n\n# Échantillonner les DataFrames pour reduire la quantite des donnees originaux dans les dataframes\nsample = 0.1\ndf_trn = df_trn.sample(frac=sample) if not df_trn.empty else df_trn\ndf_val = df_val.sample(frac=sample) if not df_val.empty else df_val\ndf_tst = df_tst.sample(frac=sample) if not df_tst.empty else df_tst\n\n# Afficher les tailles des DataFrames échantillonnés\nprint(len(df_trn), len(df_val), len(df_tst))","metadata":{"id":"FiWJuOr4I0K6","executionInfo":{"status":"ok","timestamp":1723802026225,"user_tz":-60,"elapsed":8782,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"374bf304-8cea-4fc4-8a1a-3360d9de8b30","execution":{"iopub.status.busy":"2024-08-27T08:19:32.543356Z","iopub.execute_input":"2024-08-27T08:19:32.543986Z","iopub.status.idle":"2024-08-27T08:19:40.745178Z","shell.execute_reply.started":"2024-08-27T08:19:32.543948Z","shell.execute_reply":"2024-08-27T08:19:40.744284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Afficher les 5 premiers lignes du dataframe train****","metadata":{}},{"cell_type":"code","source":"df_trn.head()","metadata":{"id":"KBbFSEY6I21b","executionInfo":{"status":"ok","timestamp":1723802026225,"user_tz":-60,"elapsed":18,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"c3d97196-f939-4d08-8792-e0af9a13d165","execution":{"iopub.status.busy":"2024-08-27T08:19:45.713854Z","iopub.execute_input":"2024-08-27T08:19:45.714230Z","iopub.status.idle":"2024-08-27T08:19:45.728772Z","shell.execute_reply.started":"2024-08-27T08:19:45.714193Z","shell.execute_reply":"2024-08-27T08:19:45.727791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## DATA Cleaning","metadata":{}},{"cell_type":"markdown","source":"****Enlever les caracteres non ASCII des dataframes****","metadata":{}},{"cell_type":"code","source":"#data cleaning\n# collapse\n# From https://stackoverflow.com/a/27084708/5768407\ndef is_ascii(s):\n    '''\n    Determines if une chaine donnee contient que les ascii characters\n\n    :param s: the string to check\n    :returns: whether or not the given string contains only ascii characters\n    '''\n    try:\n        s.encode(encoding='utf-8').decode('ascii') # encode(encoding='utf-8') : Cette méthode convertit la chaîne s en un format binaire (bytes) en utilisant l'encodage UTF-8\n    except UnicodeDecodeError:\n        return False\n    else:\n        return True\n\ndf_trn = df_trn[df_trn['mthd'].apply(lambda x: is_ascii(x))]\ndf_val = df_val[df_val['mthd'].apply(lambda x: is_ascii(x))]\ndf_tst = df_tst[df_tst['mthd'].apply(lambda x: is_ascii(x))]\n\ndf_trn = df_trn[df_trn['cmt'].apply(lambda x: is_ascii(x))]\ndf_val = df_val[df_val['cmt'].apply(lambda x: is_ascii(x))]\ndf_tst = df_tst[df_tst['cmt'].apply(lambda x: is_ascii(x))]\n\nlen(df_trn), len(df_val), len(df_tst)","metadata":{"id":"vyUAdG6SI6LR","executionInfo":{"status":"ok","timestamp":1723802026225,"user_tz":-60,"elapsed":6,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"9d48c7aa-0834-48f0-9c22-43b74c591bcf","execution":{"iopub.status.busy":"2024-08-27T08:19:49.130672Z","iopub.execute_input":"2024-08-27T08:19:49.131303Z","iopub.status.idle":"2024-08-27T08:19:49.287098Z","shell.execute_reply.started":"2024-08-27T08:19:49.131257Z","shell.execute_reply":"2024-08-27T08:19:49.286153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"On voit bien que la longeur des dataframes n'a pas changer donc on peut dire que ses dernieres ne contiennent pas des caracteres non ascii","metadata":{}},{"cell_type":"markdown","source":"****Tester la presence des valeurs manquantes dans le dataframe d'entrainement****","metadata":{}},{"cell_type":"code","source":"# Charger le DataFrame\npath = Path('/kaggle/input/code_comments/data/data/train.json')\ndf = jsonl_to_dataframe(path)\n\n# Identifier les valeurs manquantes\nmissing_values = df.isna()\nprint(\"DataFrame des valeurs manquantes :\")\nprint(missing_values)\n\n#la somme des valeurs manquantes par colonne\nmissing_values_sum = df.isna().sum()\nprint(\"\\nNombre de valeurs manquantes par colonne :\")\nprint(missing_values_sum)\n\n# le nombre total de valeurs manquantes\ntotal_missing_values = df.isna().sum().sum()\nprint(\"\\nNombre total de valeurs manquantes :\")\nprint(total_missing_values)","metadata":{"id":"HxqfD3YuI8rM","executionInfo":{"status":"ok","timestamp":1723802032568,"user_tz":-60,"elapsed":6347,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"983352e4-c56f-4fe7-dc60-a6a122fa6b50","execution":{"iopub.status.busy":"2024-08-27T08:19:53.963727Z","iopub.execute_input":"2024-08-27T08:19:53.964570Z","iopub.status.idle":"2024-08-27T08:19:57.769178Z","shell.execute_reply.started":"2024-08-27T08:19:53.964530Z","shell.execute_reply":"2024-08-27T08:19:57.768139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Heureusement notre dataframe d'entrainement ne contient pas des valeurs manquantes","metadata":{}},{"cell_type":"markdown","source":"****Graphe pour visualiser les valeurs manquantes****","metadata":{}},{"cell_type":"code","source":"# Afficher un heatmap des valeurs manquantes\nplt.figure(figsize=(8, 6))\nsns.heatmap(df.isna(), cbar=False, cmap='viridis')\nplt.title(\"Heatmap des Valeurs Manquantes\")\nplt.show()","metadata":{"id":"NUb599DdJAth","executionInfo":{"status":"ok","timestamp":1723802035803,"user_tz":-60,"elapsed":3237,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"88b868b6-8c77-4bf8-8a65-ab79497976d9","execution":{"iopub.status.busy":"2024-08-27T08:20:01.979630Z","iopub.execute_input":"2024-08-27T08:20:01.980018Z","iopub.status.idle":"2024-08-27T08:20:03.383187Z","shell.execute_reply.started":"2024-08-27T08:20:01.979981Z","shell.execute_reply":"2024-08-27T08:20:03.382289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def has_code(cmt: str) -> bool:\n    '''\n    Determinine if the given comment contains the HTML <code> tag\n\n    :param cmt: the comment to check whether it contains the HTML <code> tag\n    :returns: whether or not the given comment contains the HTML <code> tag\n    '''\n    if '<code>' in cmt: return True\n    else: return False\n\ndf_trn = df_trn[~df_trn['cmt'].apply(lambda x: has_code(x))]\ndf_val = df_val[~df_val['cmt'].apply(lambda x: has_code(x))]\ndf_tst = df_tst[~df_tst['cmt'].apply(lambda x: has_code(x))]\n\nlen(df_trn), len(df_val), len(df_tst)","metadata":{"id":"CZ750g48JBd7","executionInfo":{"status":"ok","timestamp":1723802035803,"user_tz":-60,"elapsed":9,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"ef4a210a-2bc2-40aa-a46f-67853f1f79e7","execution":{"iopub.status.busy":"2024-08-27T08:20:09.593155Z","iopub.execute_input":"2024-08-27T08:20:09.593555Z","iopub.status.idle":"2024-08-27T08:20:09.653997Z","shell.execute_reply.started":"2024-08-27T08:20:09.593515Z","shell.execute_reply":"2024-08-27T08:20:09.653001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" ****Ce code a pour but de nettoyer les commentaires en supprimant toutes les balises HTML présentes dans le texte des commentaires.****","metadata":{}},{"cell_type":"code","source":"def clean_html(cmt: str) -> str:\n    '''\n    Remove any HTML tags from a given comment\n\n    :param cmt: the comment to remove any HTML tags from\n    :returns: the comment with any HTML tags removed\n    '''\n    result = re.sub(r\"<.?span[^>]*>|<.?code[^>]*>|<.?p[^>]*>|<.?hr[^>]*>|<.?h[1-3][^>]*>|<.?a[^>]*>|<.?b[^>]*>|<.?blockquote[^>]*>|<.?del[^>]*>|<.?dd[^>]*>|<.?dl[^>]*>|<.?dt[^>]*>|<.?em[^>]*>|<.?i[^>]*>|<.?img[^>]*>|<.?kbd[^>]*>|<.?li[^>]*>|<.?ol[^>]*>|<.?pre[^>]*>|<.?s[^>]*>|<.?sup[^>]*>|<.?sub[^>]*>|<.?strong[^>]*>|<.?strike[^>]*>|<.?ul[^>]*>|<.?br[^>]*>\", \"\", cmt)\n    return result\n\ndf_trn.cmt = df_trn.cmt.apply(clean_html)\ndf_val.cmt = df_val.cmt.apply(clean_html)\ndf_tst.cmt = df_tst.cmt.apply(clean_html)","metadata":{"id":"mIrw-ra3JEUY","executionInfo":{"status":"ok","timestamp":1723802035804,"user_tz":-60,"elapsed":9,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"01aa1b44-dd2b-47d2-e58e-836ebc075ab4","execution":{"iopub.status.busy":"2024-08-27T08:20:13.590247Z","iopub.execute_input":"2024-08-27T08:20:13.590634Z","iopub.status.idle":"2024-08-27T08:20:13.707204Z","shell.execute_reply.started":"2024-08-27T08:20:13.590596Z","shell.execute_reply":"2024-08-27T08:20:13.706396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Suppression des valeurs manquantes, des espaces doubles et des doublons****","metadata":{}},{"cell_type":"code","source":"\ndf_trn = df_trn.applymap(lambda x: ' '.join(x.split()).lower())\ndf_val = df_val.applymap(lambda x: ' '.join(x.split()).lower())\ndf_tst = df_tst.applymap(lambda x: ' '.join(x.split()).lower())\n\ndf_trn = df_trn[~(df_trn['cmt'] == '')]\ndf_val = df_val[~(df_val['cmt'] == '')]\ndf_tst = df_tst[~(df_tst['cmt'] == '')]\n\ndf_trn = df_trn[~df_trn['cmt'].duplicated()]\ndf_val = df_val[~df_val['cmt'].duplicated()]\ndf_tst = df_tst[~df_tst['cmt'].duplicated()]\n\nlen(df_trn), len(df_val), len(df_tst)","metadata":{"id":"o8mw614RJIGy","executionInfo":{"status":"ok","timestamp":1723802035804,"user_tz":-60,"elapsed":7,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"75b9b050-e7df-4457-8467-46f241efa00b","execution":{"iopub.status.busy":"2024-08-27T08:20:17.733909Z","iopub.execute_input":"2024-08-27T08:20:17.734795Z","iopub.status.idle":"2024-08-27T08:20:18.173259Z","shell.execute_reply.started":"2024-08-27T08:20:17.734728Z","shell.execute_reply":"2024-08-27T08:20:18.172232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Résumé statistique**","metadata":{}},{"cell_type":"code","source":"# Afficher le résumé statistique\nprint(\"Résumé statistique :\")\nprint(df.describe())","metadata":{"id":"YaztGIL8JK04","executionInfo":{"status":"ok","timestamp":1723802037924,"user_tz":-60,"elapsed":2125,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"4d5a42b8-142f-4b82-c6f6-e8b32fa51dd3","execution":{"iopub.status.busy":"2024-08-27T08:20:24.118477Z","iopub.execute_input":"2024-08-27T08:20:24.118868Z","iopub.status.idle":"2024-08-27T08:20:25.196027Z","shell.execute_reply.started":"2024-08-27T08:20:24.118830Z","shell.execute_reply":"2024-08-27T08:20:25.194902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Suppression des JavaDocs des commentaires dans le DataFrame, ne laissant que la description.****","metadata":{}},{"cell_type":"code","source":"# collapse\nfrom tqdm import tqdm\ndef remove_jdocs(df: pd.DataFrame) -> pd.DataFrame:\n    '''\n    Remove the JavaDocs leaving only the description of the comment\n\n    :param df: the pandas dataframe to remove the JavaDocs from\n    :returns: a new pandas dataframe with the JavaDocs removed\n    '''\n    methods = []\n    comments = []\n    for i, row in tqdm(list(df.iterrows())):\n        comment = row[\"cmt\"]\n        comment = re.sub(\"([\\{\\[]).*?([\\)\\}])\", '', comment)\n\n\n        cleaned = []\n        for line in comment.split('\\n'):\n            if \"@\" in line: break\n            cleaned.append(line)\n        comments.append('\\n'.join(cleaned))\n        methods.append(row[\"mthd\"])\n    new_df = pd.DataFrame(zip(methods, comments), columns = [\"mthd\", \"cmt\"])\n\n    return new_df\n\ndf_trn = remove_jdocs(df_trn);\ndf_val = remove_jdocs(df_val);\ndf_tst = remove_jdocs(df_tst);","metadata":{"id":"3NzxC-EAJ07z","executionInfo":{"status":"ok","timestamp":1723802039111,"user_tz":-60,"elapsed":1192,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"9b9ac2e4-94fd-4b39-dbbf-6b8b1d66514c","execution":{"iopub.status.busy":"2024-08-27T08:20:28.957312Z","iopub.execute_input":"2024-08-27T08:20:28.958053Z","iopub.status.idle":"2024-08-27T08:20:32.798420Z","shell.execute_reply.started":"2024-08-27T08:20:28.958015Z","shell.execute_reply":"2024-08-27T08:20:32.797564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Voici le resultat final comment apparait le dataset","metadata":{}},{"cell_type":"code","source":"df_trn.head()","metadata":{"id":"EYpjVwfKJ5iD","executionInfo":{"status":"ok","timestamp":1723802039112,"user_tz":-60,"elapsed":16,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"d1934b75-5fa6-4fe8-ff4f-b0992f4adace","execution":{"iopub.status.busy":"2024-08-27T08:20:37.273517Z","iopub.execute_input":"2024-08-27T08:20:37.273882Z","iopub.status.idle":"2024-08-27T08:20:37.283705Z","shell.execute_reply.started":"2024-08-27T08:20:37.273848Z","shell.execute_reply":"2024-08-27T08:20:37.282776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_trn)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:20:41.327298Z","iopub.execute_input":"2024-08-27T08:20:41.327824Z","iopub.status.idle":"2024-08-27T08:20:41.334471Z","shell.execute_reply.started":"2024-08-27T08:20:41.327776Z","shell.execute_reply":"2024-08-27T08:20:41.333504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Exploring**","metadata":{}},{"cell_type":"markdown","source":" Fonction pour obtenir le nombre de chaque token dans une colonne de DataFrame, puis calcul de la distribution des longueurs de tokens et des limites maximales basées sur le 95e percentile.","metadata":{}},{"cell_type":"code","source":"def get_counter(df: pd.DataFrame, tokenizer: AutoTokenizer, col: str) -> Counter:\n    '''\n    Get the counts for each token in a given pandas dataframe column\n\n    :param df: Un dataframe de type Pandas\n    :param tokenizer: Un tokenizer de type Autotokenizer\n    dataframe\n    :param col: Une chaine de type string indiquant la colonne du dataframe a analyser\n    :returns: Le nombre des occurences de chaque token dans la colonne specifiee\n       '''\n    toks = []\n    for i, row in df.iterrows():\n      #df.iterrows() retourne un générateur qui produit des paires (index de la ligne, données de la ligne sous forme de série pandas).\n        toks.extend(tokenizer.tokenize(row[col]))\n\n    cnt = Counter()\n    for tok in toks:\n        cnt[tok] += 1\n    return cnt\n\ntokenizer = AutoTokenizer.from_pretrained('microsoft/codebert-base') #Chargement d'un tokenizer pré-entraîné basé sur le modèle microsoft/codebert-base de Hugging Face.\nmthd_cnt = get_counter(df_trn, tokenizer, 'mthd')\ncmt_cnt = get_counter(df_trn, tokenizer, 'cmt')\nmthd_lens = df_trn.mthd.apply(lambda x: len(tokenizer.tokenize(x))).values #Cette méthode (values) extrait les données de la série pandas sous forme de tableau NumPy (array).\ncmt_lens = df_trn.cmt.apply(lambda x: len(tokenizer.tokenize(x))).values\nmax_mthd_len = int(np.quantile(mthd_lens, 0.95)) #Calcul des longueurs maximales à 95% (quantiles) c'est-à-dire la valeur en dessous de laquelle se situent 95% des longueurs de tokens\nmax_cmt_len = int(np.quantile(cmt_lens, 0.95))","metadata":{"id":"Bw7mu-FTJ_yI","executionInfo":{"status":"ok","timestamp":1723802051433,"user_tz":-60,"elapsed":12333,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"8968ab2a-88ce-4bb5-db6b-f7a4e0fc2fb0","execution":{"iopub.status.busy":"2024-08-27T08:20:44.430369Z","iopub.execute_input":"2024-08-27T08:20:44.431572Z","iopub.status.idle":"2024-08-27T08:21:39.360656Z","shell.execute_reply.started":"2024-08-27T08:20:44.431522Z","shell.execute_reply":"2024-08-27T08:21:39.359800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Cette fonction trace un graphique à barres des tokens les plus fréquents, en affichant jusqu'à top_k tokens les plus courants.****","metadata":{}},{"cell_type":"code","source":"# collapse\ndef plot_counts(counts:Counter, top_k: Optional[int] = 30):\n    '''\n    :param counts: conteur des tokens et de leurs frequences\n    :param top_k: le nombre de token a afficher dans le plot\n    '''\n    labels, values = zip(*counts.most_common()[:top_k])\n\n    indexes = np.arange(len(labels))\n    width = 1\n    plt.figure(num=None, figsize=(22, 4), dpi=60, facecolor='w', edgecolor='k')\n    plt.bar(indexes, values, width)\n    plt.xticks(indexes + width * 0.5, labels)\n    plt.show()","metadata":{"id":"Z-3i1tD5KAzJ","executionInfo":{"status":"ok","timestamp":1723802051434,"user_tz":-60,"elapsed":5,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"execution":{"iopub.status.busy":"2024-08-27T08:22:46.726100Z","iopub.execute_input":"2024-08-27T08:22:46.726505Z","iopub.status.idle":"2024-08-27T08:22:46.733327Z","shell.execute_reply.started":"2024-08-27T08:22:46.726470Z","shell.execute_reply":"2024-08-27T08:22:46.732194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_counts(mthd_cnt, top_k = 30)\nplot_counts(cmt_cnt, top_k = 30)","metadata":{"id":"t7Bo36mRKDd1","executionInfo":{"status":"ok","timestamp":1723802053038,"user_tz":-60,"elapsed":1607,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"0622d16d-d085-4bf6-b8ac-bab12d1b0c8c","execution":{"iopub.status.busy":"2024-08-27T08:22:50.222796Z","iopub.execute_input":"2024-08-27T08:22:50.223624Z","iopub.status.idle":"2024-08-27T08:22:50.934004Z","shell.execute_reply.started":"2024-08-27T08:22:50.223586Z","shell.execute_reply":"2024-08-27T08:22:50.933051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****les statistiques descriptives (moyenne, médiane, écart type, min, max, 25e et 75e percentiles)****","metadata":{}},{"cell_type":"code","source":"# Calcul des statistiques descriptives pour les longueurs des tokens\ndef descriptive_stats(lengths):\n    return {\n        'mean': np.mean(lengths), #moyenne\n        'median': np.median(lengths), #mediane\n        'std_dev': np.std(lengths), #ecart_type\n        'min': np.min(lengths),\n        'max': np.max(lengths),\n        '25th_percentile': np.percentile(lengths, 25), #premier quartile (Q1)\n        '75th_percentile': np.percentile(lengths, 75) #troisième quartile (Q3)\n    }\n\nmthd_stats = descriptive_stats(mthd_lens)\ncmt_stats = descriptive_stats(cmt_lens)\n\nprint(\"Method Lengths Statistics:\", mthd_stats)\nprint(\"Comment Lengths Statistics:\", cmt_stats)\n","metadata":{"id":"XtqoQdvjKGHk","executionInfo":{"status":"ok","timestamp":1723802053038,"user_tz":-60,"elapsed":10,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"a3255c20-181d-49b5-d2d6-1fac4a737797","execution":{"iopub.status.busy":"2024-08-27T08:23:26.394246Z","iopub.execute_input":"2024-08-27T08:23:26.394975Z","iopub.status.idle":"2024-08-27T08:23:26.406690Z","shell.execute_reply.started":"2024-08-27T08:23:26.394934Z","shell.execute_reply":"2024-08-27T08:23:26.405642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Top Tokens in Methods:\", mthd_cnt.most_common(30))\nprint(\"Top Tokens in Comments:\", cmt_cnt.most_common(30))","metadata":{"id":"JA_vzkN3KI-s","executionInfo":{"status":"ok","timestamp":1723802053038,"user_tz":-60,"elapsed":7,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"0272fa29-23ea-4a71-8085-b4f36c7ea0bc","execution":{"iopub.status.busy":"2024-08-27T08:23:32.410454Z","iopub.execute_input":"2024-08-27T08:23:32.410849Z","iopub.status.idle":"2024-08-27T08:23:32.424673Z","shell.execute_reply.started":"2024-08-27T08:23:32.410815Z","shell.execute_reply":"2024-08-27T08:23:32.423609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Création d'un histogramme pour comparer la distribution des longueurs des tokens des méthodes et des commentaires****","metadata":{}},{"cell_type":"code","source":"# Histogramme\nplt.hist(mthd_lens, bins=50, alpha=0.7, label='Method Lengths')\nplt.hist(cmt_lens, bins=50, alpha=0.7, label='Comment Lengths')\nplt.legend()\nplt.xlabel('Number of Tokens')\nplt.ylabel('Frequency')\nplt.title('Distribution of Token Lengths')\nplt.show()\n\n# Box Plot\nplt.boxplot([mthd_lens, cmt_lens], labels=['Methods', 'Comments'])\nplt.ylabel('Number of Tokens')\nplt.title('Box Plot of Token Lengths')\nplt.show()","metadata":{"id":"9AWtQJRmKLY5","executionInfo":{"status":"ok","timestamp":1723802054143,"user_tz":-60,"elapsed":1109,"user":{"displayName":"rachida rachdaoui","userId":"00631738997420655811"}},"outputId":"269a5c02-4b3f-4a40-e5dd-f87f57a9294f","execution":{"iopub.status.busy":"2024-08-27T08:23:40.525529Z","iopub.execute_input":"2024-08-27T08:23:40.525928Z","iopub.status.idle":"2024-08-27T08:23:41.306524Z","shell.execute_reply.started":"2024-08-27T08:23:40.525892Z","shell.execute_reply":"2024-08-27T08:23:41.305528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Remarque :**\n\n---\n\nOn observe que la plupart des méthodes et des commentaires ont une longueur très courte (nombre de tokens faible), ce qui est représenté par la grande barre à gauche du graphique (proche de 0).\nPour le box plot :\nLa ligne horizontale à l'intérieur de chaque boîte représente la médiane du nombre de tokens pour les méthodes et les commentaires.Les boîtes représentent les quartiles, c'est-à-dire que 50 % des données se trouvent à l'intérieur de la boîte.En fin on peut dire que le Box plot montre clairement que les méthodes de code ont une variabilité de longueur beaucoup plus grande que les commentaires, avec plusieurs méthodes étant des outliers très longs.","metadata":{}},{"cell_type":"markdown","source":"****Calcul de la similarité cosinus entre les commentaires en utilisant TF-IDF pour transformer le texte en vecteurs****","metadata":{}},{"cell_type":"code","source":"\"\"\"on a eleminer ce code a cause de la grande quantite de donnees car cela demande une grande puissance de calcule\"\"\"\n# from sklearn.feature_extraction.text import TfidfVectorizer\n# from sklearn.metrics.pairwise import cosine_similarity\n# import seaborn as sns\n\n# # Calcul de la similarité cosinus\n# vectorizer = TfidfVectorizer()\n# X = vectorizer.fit_transform(df_trn['cmt'])\n# similarity_matrix = cosine_similarity(X)\n\n# # Affichage de la matrice de similarité\n# sns.heatmap(similarity_matrix, cmap='coolwarm')\n# plt.title('Cosine Similarity Matrix')\n# plt.show()","metadata":{"id":"8Oz7ttQyKPBW","execution":{"iopub.status.busy":"2024-08-26T12:53:46.015340Z","iopub.execute_input":"2024-08-26T12:53:46.016281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model Training**","metadata":{}},{"cell_type":"markdown","source":"--> Telechargment de quelques modules necessaires pour l'entrainement","metadata":{}},{"cell_type":"code","source":"!pip install torch datasets","metadata":{"id":"6cwhSn4EXHfG","execution":{"iopub.status.busy":"2024-08-27T08:23:50.941562Z","iopub.execute_input":"2024-08-27T08:23:50.941968Z","iopub.status.idle":"2024-08-27T08:24:04.387039Z","shell.execute_reply.started":"2024-08-27T08:23:50.941923Z","shell.execute_reply":"2024-08-27T08:24:04.385629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir java","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:24:36.511475Z","iopub.execute_input":"2024-08-27T08:24:36.511936Z","iopub.status.idle":"2024-08-27T08:24:37.534113Z","shell.execute_reply.started":"2024-08-27T08:24:36.511895Z","shell.execute_reply":"2024-08-27T08:24:37.533038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp  /kaggle/input/fichierprojet/projet/model.py /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:24:41.917836Z","iopub.execute_input":"2024-08-27T08:24:41.918845Z","iopub.status.idle":"2024-08-27T08:24:42.962065Z","shell.execute_reply.started":"2024-08-27T08:24:41.918796Z","shell.execute_reply":"2024-08-27T08:24:42.961018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp  /kaggle/input/fichierprojet/projet/bleu.py /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:24:46.005609Z","iopub.execute_input":"2024-08-27T08:24:46.006558Z","iopub.status.idle":"2024-08-27T08:24:47.050705Z","shell.execute_reply.started":"2024-08-27T08:24:46.006508Z","shell.execute_reply":"2024-08-27T08:24:47.049549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp  /kaggle/input/fichierprojet/projet/run.py /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:24:49.807443Z","iopub.execute_input":"2024-08-27T08:24:49.807897Z","iopub.status.idle":"2024-08-27T08:24:50.856636Z","shell.execute_reply.started":"2024-08-27T08:24:49.807856Z","shell.execute_reply":"2024-08-27T08:24:50.855644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\ndf_trn['code_tokens'] = df_trn.mthd.apply(lambda x: x.split()) #Ajouter une nouvelle colonne des tokens au dataframe\ndf_trn['docstring_tokens'] = df_trn.cmt.apply(lambda x: x.split())\nwith open('java/train.jsonl','w') as f:\n    for _, row in df_trn.iterrows():\n        f.write(json.dumps(row.to_dict()) + '\\n') #Convertir les row en dictionnaire puis pour l'ecriture dans le fichier json il faut avoir un format chaine de caractere c'est le role de dump\n\ndf_val['code_tokens'] = df_val.mthd.apply(lambda x: x.split())\ndf_val['docstring_tokens'] = df_val.cmt.apply(lambda x: x.split())\nwith open('java/valid.jsonl','w') as f:\n    for _, row in df_val.iterrows():\n        f.write(json.dumps(row.to_dict()) + '\\n')\n\ndf_tst['code_tokens'] = df_tst.mthd.apply(lambda x: x.split())\ndf_tst['docstring_tokens'] = df_tst.cmt.apply(lambda x: x.split())\nwith open('java/test.jsonl','w') as f:\n    for _, row in df_tst.iterrows():\n        f.write(json.dumps(row.to_dict()) + '\\n')","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:25:40.127077Z","iopub.execute_input":"2024-08-27T08:25:40.127838Z","iopub.status.idle":"2024-08-27T08:25:45.027939Z","shell.execute_reply.started":"2024-08-27T08:25:40.127799Z","shell.execute_reply":"2024-08-27T08:25:45.026920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'objectif de ce code est de préparer les données pour un modèle en créant des tokens pour le code source et les commentaires, puis les sauvegarder au format .jsonl pour une utilisation ultérieure.","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/microsoft/CodeXGLUE.git\n!cd CodeXGLUE","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:25:53.445845Z","iopub.execute_input":"2024-08-27T08:25:53.446316Z","iopub.status.idle":"2024-08-27T08:26:14.269487Z","shell.execute_reply.started":"2024-08-27T08:25:53.446269Z","shell.execute_reply":"2024-08-27T08:26:14.268476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Le dépôt CodeXGLUE de Microsoft contient des ressources, des codes, et des jeux de données pour diverses tâches liées au traitement automatique du langage naturel (NLP) et à la programmation assistée par l'intelligence artificielle.(Optionnel)","metadata":{}},{"cell_type":"code","source":"lang = 'java' # programming language\nlr = 5e-5\nbatch_size = 8 # change depending on the GPU Colab gives you\nbeam_size = 10\nsource_length = 256\ntarget_length = 50\ndata_dir = '.'\noutput_dir = f'model/{lang}'\ntrain_file = f'{data_dir}/{lang}/train.jsonl'\ndev_file = f'{data_dir}/{lang}/valid.jsonl'\nepochs = 10\npretrained_model = 'microsoft/codebert-base'\n\n! python /kaggle/working/run.py \\\n    --do_train \\\n    --do_eval \\\n    --do_lower_case \\\n    --model_type roberta \\\n    --model_name_or_path {pretrained_model} \\\n    --train_filename {train_file} \\\n    --dev_filename {dev_file} \\\n    --output_dir {output_dir} \\\n    --max_source_length {source_length} \\\n    --max_target_length {target_length} \\\n    --beam_size {beam_size} \\\n    --train_batch_size {batch_size} \\\n    --eval_batch_size {batch_size} \\\n    --learning_rate {lr} \\\n    --num_train_epochs {epochs}","metadata":{"execution":{"iopub.status.busy":"2024-08-27T08:26:25.427093Z","iopub.execute_input":"2024-08-27T08:26:25.427932Z","iopub.status.idle":"2024-08-27T14:41:27.759048Z","shell.execute_reply.started":"2024-08-27T08:26:25.427889Z","shell.execute_reply":"2024-08-27T14:41:27.757994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'objectif de ce code est de fine-tuner le modèle CodeBERT(de Hugging face Transformers) sur un ensemble de données spécifiques","metadata":{}},{"cell_type":"code","source":"batch_size=64\ndev_file=f\"{data_dir}/{lang}/valid.jsonl\"\ntest_file=f\"{data_dir}/{lang}/test.jsonl\"\ntest_model=f\"{output_dir}/checkpoint-best-bleu/pytorch_model.bin\" #checkpoint for test\n\n! python /kaggle/working/run.py \\\n    --do_test \\\n    --model_type roberta \\\n    --model_name_or_path microsoft/codebert-base \\\n    --load_model_path {test_model} \\\n    --dev_filename {dev_file} \\\n    --test_filename {test_file} \\\n    --output_dir {output_dir} \\\n    --max_source_length {source_length} \\\n    --max_target_length {target_length} \\\n    --beam_size {beam_size} \\\n    --eval_batch_size {batch_size}","metadata":{"execution":{"iopub.status.busy":"2024-08-27T14:44:57.107465Z","iopub.execute_input":"2024-08-27T14:44:57.107927Z","iopub.status.idle":"2024-08-27T15:08:26.427633Z","shell.execute_reply.started":"2024-08-27T14:44:57.107886Z","shell.execute_reply":"2024-08-27T15:08:26.426363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"L'objectif de ce code est de tester le modèle CodeBERT qui a été entraîné, en utilisant un ensemble de données de test pour évaluer sa performance.","metadata":{}},{"cell_type":"code","source":"import re\n\ndef detect_classes(file_path):\n    with open(file_path, 'r') as file:\n        content = file.read()\n\n    class_pattern = re.compile(r'class\\s+(\\w+)\\s*\\(.*?\\):')\n    classes = class_pattern.findall(content)\n\n    return classes\n\nfile_path = './model.py'\nclasses = detect_classes(file_path)\nprint(\"Classes found:\", classes)","metadata":{"id":"hcFPaZzjbbJM","execution":{"iopub.status.busy":"2024-08-27T15:08:48.596320Z","iopub.execute_input":"2024-08-27T15:08:48.596782Z","iopub.status.idle":"2024-08-27T15:08:48.605293Z","shell.execute_reply.started":"2024-08-27T15:08:48.596720Z","shell.execute_reply":"2024-08-27T15:08:48.604391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from model import Seq2Seq","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:08:52.247728Z","iopub.execute_input":"2024-08-27T15:08:52.248626Z","iopub.status.idle":"2024-08-27T15:08:52.254182Z","shell.execute_reply.started":"2024-08-27T15:08:52.248588Z","shell.execute_reply":"2024-08-27T15:08:52.253419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collapse\nimport torch\n\nimport torch.nn as nn\n\nfrom transformers import RobertaConfig, RobertaModel\n\nconfig = RobertaConfig.from_pretrained(pretrained_model)\nencoder = RobertaModel.from_pretrained(pretrained_model, config = config)\ndecoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\ndecoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\nmodel = Seq2Seq(encoder = encoder,decoder = decoder,config=config,\n                beam_size=beam_size,max_length=target_length,\n                sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\nmodel.load_state_dict(torch.load(Path(output_dir)/\"checkpoint-last/pytorch_model.bin\"))\nmodel.to('cuda')","metadata":{"id":"VYuAun8YcQZX","execution":{"iopub.status.busy":"2024-08-27T15:08:55.933210Z","iopub.execute_input":"2024-08-27T15:08:55.933608Z","iopub.status.idle":"2024-08-27T15:08:58.991816Z","shell.execute_reply.started":"2024-08-27T15:08:55.933572Z","shell.execute_reply":"2024-08-27T15:08:58.990888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ce code initialise et configure le modèle Seq2Seq basé sur Roberta pour une tâche de génération de séquence. Il est constitué d'un encodeur **Roberta** pré-entraîné et d'un décodeur **Transformer**. Les poids du modèle sont chargés à partir d'un checkpoint sauvegardé, et le modèle est transféré sur le GPU pour exécuter des inférences ou pour une nouvelle phase de test ou d'entraînement.","metadata":{}},{"cell_type":"code","source":"idx = 0","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:09:07.733519Z","iopub.execute_input":"2024-08-27T15:09:07.734388Z","iopub.status.idle":"2024-08-27T15:09:07.738399Z","shell.execute_reply.started":"2024-08-27T15:09:07.734347Z","shell.execute_reply":"2024-08-27T15:09:07.737461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# collapse\nfrom run import convert_examples_to_features, Example\n\nclass Args:\n    max_source_length = source_length\n    max_target_length = target_length\n\nargs = Args()\n\ndef get_preds(df: pd.DataFrame):\n    ps = []\n    for idx, row in tqdm(df.iterrows(), total=len(df)):\n        examples = [\n            Example(idx, source = row.mthd, target = row.cmt)\n        ]\n        eval_features = convert_examples_to_features(\n            examples, tokenizer, args, stage='test'\n        )\n        source_ids = torch.tensor(eval_features[0].source_ids, dtype = torch.long).unsqueeze(0).to('cuda')\n        source_mask = torch.tensor(eval_features[0].source_mask, dtype = torch.long).unsqueeze(0).to('cuda')\n\n        with torch.no_grad():\n            preds = model(source_ids = source_ids, source_mask = source_mask)\n            for pred in preds:\n                t = pred[0].cpu().numpy()\n                t = list(t)\n                if 0 in t:\n                    t = t[:t.index(0)]\n                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n                ps.append(text)\n\n    return ps","metadata":{"id":"hz3dY3Iwci5D","execution":{"iopub.status.busy":"2024-08-27T15:09:17.930101Z","iopub.execute_input":"2024-08-27T15:09:17.930500Z","iopub.status.idle":"2024-08-27T15:09:17.940572Z","shell.execute_reply.started":"2024-08-27T15:09:17.930461Z","shell.execute_reply":"2024-08-27T15:09:17.939615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La fonction get_preds sert à générer des prédictions de texte à partir des méthodes présentes dans un DataFrame. Chaque méthode est transformée en séquence d'IDs, passée à travers le modèle **Seq2Seq** pour obtenir une prédiction, qui est ensuite décodée en texte. Ce texte est ensuite collecté et renvoyé sous forme de liste de prédictions.","metadata":{}},{"cell_type":"code","source":"\"\"\" ce code prend les 10 premières lignes du DataFrame, génère des commentaires pour chacune en utilisant notre modèle\"\"\"\ndf_val = df_val.reset_index()\npreds = get_preds(df_val.head(10))\nfor idx, row in df_val.head(10).iterrows():\n    print('Code:', row.mthd)\n    print('Original Comment:', row.cmt)\n    print('Generated Comment:', preds[idx])\n    print('='*40)","metadata":{"id":"iztzNHdhcpHQ","execution":{"iopub.status.busy":"2024-08-27T15:09:21.931879Z","iopub.execute_input":"2024-08-27T15:09:21.932280Z","iopub.status.idle":"2024-08-27T15:09:28.087072Z","shell.execute_reply.started":"2024-08-27T15:09:21.932235Z","shell.execute_reply":"2024-08-27T15:09:28.086126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_losses(df: pd.DataFrame):\n    ps = []\n    losses = []\n    for idx, row in tqdm(df.iterrows(), total=len(df)):\n        examples = [\n            Example(idx, source = row.mthd, target = row.cmt)\n        ]\n        eval_features = convert_examples_to_features(\n            examples, tokenizer, args, stage='test'\n        )\n        source_ids = torch.tensor([f.source_ids for f in eval_features], dtype = torch.long).to('cuda')\n        source_mask = torch.tensor([f.source_mask for f in eval_features], dtype = torch.long).to('cuda')\n        target_ids = torch.tensor([f.target_ids for f in eval_features], dtype = torch.long).to('cuda')\n        target_mask = torch.tensor([f.target_mask for f in eval_features], dtype = torch.long).to('cuda')\n\n        with torch.no_grad():\n            _, loss, _ = model(\n                source_ids = source_ids, source_mask = source_mask,\n                target_ids = target_ids, target_mask = target_mask\n            )\n            preds = model(source_ids = source_ids, source_mask = source_mask)\n            for pred in preds:\n                t = pred[0].cpu().numpy()\n                t = list(t)\n                if 0 in t:\n                    t = t[:t.index(0)]\n                text = tokenizer.decode(t,clean_up_tokenization_spaces=False)\n                ps.append(text)\n                losses.append(loss.item())\n\n    return ps, losses","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:10:21.334613Z","iopub.execute_input":"2024-08-27T15:10:21.335827Z","iopub.status.idle":"2024-08-27T15:10:21.346161Z","shell.execute_reply.started":"2024-08-27T15:10:21.335784Z","shell.execute_reply":"2024-08-27T15:10:21.345127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"La fonction get_preds_losses traite chaque ligne d'un DataFrame pour générer des prédictions et calculer les pertes en utilisant le modèle","metadata":{}},{"cell_type":"code","source":"df_head = df_val.copy()\nps, losses = get_preds_losses(df_head)\ndf_head['pred'] = ps\ndf_head['loss'] = losses\ndf_sorted_losses = df_head.sort_values('loss', ascending = False)\n\nfor _, row in df_sorted_losses.head(10).iterrows():\n    print('Code:', row.mthd)\n    print('Original Comment:', row.cmt)\n    print('Generated Comment:', row.pred)\n    print(row.loss)\n    print('='*40)","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:10:25.113484Z","iopub.execute_input":"2024-08-27T15:10:25.113902Z","iopub.status.idle":"2024-08-27T15:32:40.568907Z","shell.execute_reply.started":"2024-08-27T15:10:25.113863Z","shell.execute_reply":"2024-08-27T15:32:40.567899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ce code génère des prédictions et calcule des pertes pour chaque exemple dans le DataFrame df_val. Ensuite, il ajoute ces résultats au DataFrame, trie les exemples par ordre décroissant des pertes, et affiche les 10 exemples avec les pertes les plus élevées","metadata":{}},{"cell_type":"code","source":"from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nimport nltk\n\nnltk.download('punkt')  # Téléchargez les ressources nécessaires pour le tokenization\n\ndef calculate_bleu(reference, hypothesis):\n    if len(hypothesis) == 0:  # Vérifie si l'hypothèse est vide\n        return 0.0\n    smoothie = SmoothingFunction().method4\n    try:\n        score = sentence_bleu([reference], hypothesis, smoothing_function=smoothie)\n    except ZeroDivisionError:  # Catch division by zero errors\n        score = 0.0\n    return score\n\ndf_head['bleu'] = df_head.apply(lambda row: calculate_bleu(row.cmt.split(), row.pred.split()), axis=1)\n\nprint(f\"Score BLEU moyen : {df_head['bleu'].mean()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:41:07.900374Z","iopub.execute_input":"2024-08-27T15:41:07.900772Z","iopub.status.idle":"2024-08-27T15:41:08.585112Z","shell.execute_reply.started":"2024-08-27T15:41:07.900715Z","shell.execute_reply":"2024-08-27T15:41:08.584140Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ce code a pour objectif de calculer le score **BLEU** (Bilingual Evaluation Understudy) pour évaluer la qualité des commentaires générés par votre modèle par rapport aux commentaires de référence","metadata":{}},{"cell_type":"markdown","source":"**NB:**\nun score BLEU seul ne donne pas une image complète de la qualité du modèle, car il ne prend pas en compte la qualité sémantique ou la pertinence des commentaires générés.","metadata":{}},{"cell_type":"code","source":"!pip install rouge-score","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:41:14.234704Z","iopub.execute_input":"2024-08-27T15:41:14.235577Z","iopub.status.idle":"2024-08-27T15:41:29.722841Z","shell.execute_reply.started":"2024-08-27T15:41:14.235538Z","shell.execute_reply":"2024-08-27T15:41:29.721674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from rouge_score import rouge_scorer\n\n# Initialiser le calculateur ROUGE\nscorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n\ndef calculate_rouge(reference, hypothesis):\n    scores = scorer.score(reference, hypothesis)\n    return scores\n\n# Appliquer le calcul ROUGE sur chaque ligne du DataFrame\ndf_head['rouge_scores'] = df_head.apply(lambda row: calculate_rouge(row.cmt, row.pred), axis=1)\n\n# Extraire les scores ROUGE-1, ROUGE-2, et ROUGE-L\ndf_head['rouge1'] = df_head['rouge_scores'].apply(lambda x: x['rouge1'].fmeasure)\ndf_head['rouge2'] = df_head['rouge_scores'].apply(lambda x: x['rouge2'].fmeasure)\ndf_head['rougeL'] = df_head['rouge_scores'].apply(lambda x: x['rougeL'].fmeasure)\n\n# Afficher les scores moyens\nprint(f\"Score ROUGE-1 moyen : {df_head['rouge1'].mean()}\")\nprint(f\"Score ROUGE-2 moyen : {df_head['rouge2'].mean()}\")\nprint(f\"Score ROUGE-L moyen : {df_head['rougeL'].mean()}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-27T15:41:32.771675Z","iopub.execute_input":"2024-08-27T15:41:32.772094Z","iopub.status.idle":"2024-08-27T15:41:35.830543Z","shell.execute_reply.started":"2024-08-27T15:41:32.772050Z","shell.execute_reply":"2024-08-27T15:41:35.829496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Interpretation des resultats**:\n---\n**ROUGE-1 moyen (0.34) :** Ce score mesure la correspondance des unigrams (mots individuels) entre le texte de référence et le texte généré. Un score de 0.34 indique qu'environ 34% des unigrams du texte généré se retrouvent dans le texte de référence. Ce score est relativement modéré, suggérant une certaine similarité au niveau des mots individuels.\n\n**ROUGE-2 moyen (0.15) :** Ce score mesure la correspondance des bigrams (paires de mots consécutifs) entre le texte de référence et le texte généré. Un score de 0.15 est plus bas que celui de ROUGE-1, ce qui est habituel, car la correspondance des bigrams est plus difficile à obtenir. Ce score indique que seulement 15% des bigrams correspondent, ce qui peut signifier que la structure des phrases diffère entre le texte généré et le texte de référence.\n\n**ROUGE-L moyen (0.33) :** Ce score mesure la correspondance de la plus longue sous-séquence commune (LCS) entre le texte de référence et le texte généré. Un score de 0.33 est comparable à ROUGE-1, ce qui suggère que la séquence générale des mots dans le texte généré est similaire à celle du texte de référence, mais sans correspondance parfaite.","metadata":{}},{"cell_type":"markdown","source":"## **Fin**","metadata":{}},{"cell_type":"markdown","source":"Ce projet a porté sur La Generation Automatique des Code JAVA. Tout au long du projet, nous avons développé et évalué un modèle de génération automatique de commentaires en utilisant Le fameux CodeBert en passant par plusieurs etapes essentiels a savoir de Data cleaning ,Data processing et L'entrainnement du modele.","metadata":{}}]}